{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terminal Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *\n",
    "# chat_with_llama(\"\"\"\"\"\", use_tool=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SERP_API_KEY\"] = \"5affe20ad27423ecb9954ffa3151680c42adadca\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "User message: Search the web for latest tweet from Sam Altman\n",
      "==================================================\n",
      "Web Search Tool\n"
     ]
    }
   ],
   "source": [
    "# OverAll: Search for Snake Game implementation online -> write content into local script -> run & debug & test\n",
    "# 1. Web Search + Voyager\n",
    "out = chat_with_llama(\"\"\"Search the web for latest tweet from Sam Altman\"\"\", use_tool=True)\n",
    "# 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'sam altman twitter - The Economic Times - IndiaTimes',\n",
       " 'link': 'https://economictimes.indiatimes.com/topic/sam-altman-twitter',\n",
       " 'snippet': 'sam altman twitter Latest Breaking News, Pictures, Videos, and Special Reports from The Economic Times. sam altman twitter Blogs, Comments and Archive News ...',\n",
       " 'position': 8}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "User message: read local file street_fighter.py\n",
      "==================================================\n",
      "File Reader Tool\n",
      "print(\"Ryu: Hadouken!\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src import *\n",
    "\n",
    "# Each request can NOT be too lenghty, otherwise function call will not work properly\n",
    "\n",
    "#\n",
    "# Read\n",
    "read_out = chat_with_llama(\"read local file street_fighter.py\")\n",
    "# Run  \n",
    "run_out = chat_with_llama(\"run local file street_fighter.py\")\n",
    "# Write\n",
    "write_in = chat_with_llama(\"write the next 10 lines of street figher game into local file street_fighter.py\")\n",
    "print(out)\n",
    "\n",
    "# Loop back the observation into itself and ask for the next step\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "User message: write the next 10 lines of street figher game into local file street_fighter.py\n",
      "==================================================\n",
      "File Writer Tool\n"
     ]
    }
   ],
   "source": [
    "out = chat_with_llama(\"write the next 10 lines of street figher game into local file street_fighter.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.action import *\n",
    "\n",
    "GROQ_API_KEY = os.environ[\"GROQ_API_KEY\"]\n",
    "E2B_API_KEY = os.environ[\"E2B_API_KEY\"]\n",
    "ANTHROPIC_API_KEY = os.environ[\"ANTHROPIC_API_KEY\"]\n",
    "groq_client = Groq(api_key=GROQ_API_KEY)\n",
    "\n",
    "\n",
    "user_message = \"Write a snake game into a local file named snake_game.py\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": user_message}\n",
    "]\n",
    "\n",
    "MODEL_NAME = \"llama3-70b-8192\"\n",
    "\n",
    "response = groq_client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    "    max_tokens=4096,\n",
    ")\n",
    "\n",
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1239661712.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    .....\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from src import *\n",
    "\n",
    "\n",
    "request = \"run the file snake.py and report the issue\"\n",
    "out = chat_with_llama(request)\n",
    "\n",
    "\n",
    "has_bug = \"Error\" in out\n",
    "if has_bug:\n",
    "    print(\"Please debug\")\n",
    "else:\n",
    "    print(\"think about the next step to complete {initial_goal}\")\n",
    "    ....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<async_generator object Pregel.astream at 0x123d65d50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Deeper\n",
    "from src.utils import graph\n",
    "graph.astream(\"run the file snake.py and report the issue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n",
      "Please ask me a question:\n",
      "final: (en)  you\n",
      "Final transcription received: (en)  you\n",
      "Final Transcription:   you\n",
      "Connected!\n",
      "Please ask me a question:\n",
      "partial: (en)  How is it?\n",
      "partial: (en)  How is everything?\n",
      "partial: (en)  How is everything?\n",
      "final: (en)  How is everything?\n",
      "Final transcription received: (en)  How is everything?\n",
      "Final Transcription:   How is everything?\n",
      "Connected!\n",
      "Please ask me a question:\n",
      "partial: (en)  Voila Baud\n",
      "partial: (en)  What about Don?\n",
      "partial: (en)  What about Donald Trump?\n",
      "partial: (en)  What about Donald Trump?\n",
      "final: (en)  What about Donald Trump?\n",
      "Final transcription received: (en)  What about Donald Trump?\n",
      "Final Transcription:   What about Donald Trump?\n",
      "Connected!\n",
      "Please ask me a question:\n",
      "final: (en)  Stop.\n",
      "Final transcription received: (en)  Stop.\n",
      "Final Transcription:   Stop.\n",
      "Breaking Out!!!!!!\n"
     ]
    }
   ],
   "source": [
    "from src import gladia, graph, perception, utils\n",
    "# Upon the Stop Command this break the loops\n",
    "while True:\n",
    "    question = await gladia.listen()\n",
    "    if \"Stop\" in question:\n",
    "        print(\"Breaking Out!!!!!!\")\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending name='Task-5' coro=<main() running at /var/folders/nn/nbsb8w3570zfgs23h2s0cdzm0000gn/T/ipykernel_51614/4176996416.py:90>>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ \n",
      "Search Iteration: 1 \n",
      "------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 13:55:19,327 - Surfer Agent - INFO - Navigating to Google on a new page with question: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 13:55:23,018 - Surfer Agent - INFO - Updated Agent Input: \n",
      "2024-05-08 13:55:23,019 - Surfer Agent - INFO - Action: \n",
      "1. Wait: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: \n",
      "1. Wait: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 13:55:33,304 - Surfer Agent - INFO - Updated Agent Input: \n",
      "2024-05-08 13:55:33,304 - Surfer Agent - INFO - Action: \n",
      "2. Type: ['6', 'Your search query here']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: \n",
      "2. Type: ['6', 'Your search query here']\n"
     ]
    }
   ],
   "source": [
    "from src import gladia, graph, perception, utils\n",
    "import asyncio\n",
    "import playwright\n",
    "from src import gladia, graph, perception, utils\n",
    "from playwright.async_api import async_playwright\n",
    "from src.utils import graph\n",
    "import logging\n",
    "logger = logging.getLogger(\"Surfer Agent\")\n",
    "logger.setLevel(logging.INFO)\n",
    "hander = logging.StreamHandler()\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "hander.setFormatter(formatter)\n",
    "logger.addHandler(hander)\n",
    "\n",
    "\n",
    "# Declare the global variables\n",
    "break_out = False\n",
    "if_end = False\n",
    "question = \"\"\n",
    "search_iter = 0\n",
    "\n",
    "# One Concurrent Async Process | Gradia Streaming Audio Input\n",
    "async def listen_for_stop():\n",
    "    global break_out, if_end, question\n",
    "    while True:\n",
    "        question = await gladia.listen()\n",
    "        logger.info(f\"Getting Question: {question}\")\n",
    "        if \"Stop\" in question:\n",
    "            logger.info(\"Breaking out upon hearing 'Stop'.\")\n",
    "            break_out = True\n",
    "            print(\"Breaking Out!!!!!!\")\n",
    "        if \"End\" in question:\n",
    "            logger.info(\"End the Agent upon hearing 'End'.\")\n",
    "            if_end = True\n",
    "            break\n",
    "\n",
    "async def web_voyager():\n",
    "    pass\n",
    "    global break_out, if_end, question, search_iter\n",
    "\n",
    "    while not if_end:\n",
    "        search_iter += 1\n",
    "        print(f\"------ \\nSearch Iteration: {search_iter} \\n------\")\n",
    "        browser = await async_playwright().start()\n",
    "        browser = await browser.chromium.launch(headless=False, args=None)\n",
    "\n",
    "        # Change the Starting Point for the Web-Browsing Agent\n",
    "        page = await browser.new_page()\n",
    "        _ = await page.goto(\"https://www.google.com\") # This is where we decide the starting point of the agent\n",
    "        logger.info(f\"Navigating to Google on a new page with question: {question}\")\n",
    "\n",
    "        event_stream = graph.astream(\n",
    "            {\n",
    "                \"page\": page,\n",
    "                \"input\": question,\n",
    "                \"scratchpad\": [],\n",
    "            },\n",
    "            {\n",
    "                \"recursion_limit\": 50,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        final_answer = None\n",
    "        steps = []\n",
    "        async for event in event_stream:\n",
    "            # We'll display an event stream here\n",
    "            if \"agent\" not in event:\n",
    "                continue\n",
    "            if break_out:\n",
    "                break_out = False\n",
    "                break\n",
    "            event['agent']['input'] = question # Dummny Slot-in Place for further requests from user\n",
    "            logger.info(f\"Updated Agent Input: {event['agent']['input']}\")\n",
    "\n",
    "            pred = event.get(\"agent\", {}).get(\"prediction\") or {}\n",
    "            # print(\"Event: \", event)\n",
    "            # print(\"Prediction: \\n\", pred)\n",
    "            action = pred.get(\"action\")\n",
    "            action_input = pred.get(\"args\")\n",
    "            logger.info(f\"Action: \\n{len(steps) + 1}. {action}: {action_input}\")\n",
    "            print(f\"Action: \\n{len(steps) + 1}. {action}: {action_input}\")\n",
    "            steps.append(f\"{len(steps) + 1}. {action}: {action_input}\")\n",
    "            if \"ANSWER\" in action:\n",
    "                final_answer = action_input[0]\n",
    "                logger.info(f\"Final Answer: {final_answer}\")\n",
    "                print(\"Final Answer: \", final_answer)\n",
    "                break\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # Create and run the tasks concurrently\n",
    "    task1 = asyncio.create_task(listen_for_stop())\n",
    "    task2 = asyncio.create_task(web_voyager())\n",
    "    await asyncio.gather(task1, task2)\n",
    "\n",
    "# Run the async main function\n",
    "# asyncio.run(main())\n",
    "asyncio.ensure_future(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m final_answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     39\u001b[0m steps \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m event_stream:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# We'll display an event stream here\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m event:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/langgraph/pregel/__init__.py:893\u001b[0m, in \u001b[0;36mPregel.astream\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before_nodes, interrupt_after_nodes, debug)\u001b[0m\n\u001b[1;32m    879\u001b[0m futures \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    880\u001b[0m     [\n\u001b[1;32m    881\u001b[0m         asyncio\u001b[38;5;241m.\u001b[39mcreate_task(_aconsume(proc\u001b[38;5;241m.\u001b[39mastream(\u001b[38;5;28minput\u001b[39m, config)))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    888\u001b[0m     ]\n\u001b[1;32m    889\u001b[0m )\n\u001b[1;32m    891\u001b[0m \u001b[38;5;66;03m# execute tasks, and wait for one to fail or all to finish.\u001b[39;00m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;66;03m# each task is independent from all other concurrent tasks\u001b[39;00m\n\u001b[0;32m--> 893\u001b[0m done, inflight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mwait(\n\u001b[1;32m    894\u001b[0m     futures,\n\u001b[1;32m    895\u001b[0m     return_when\u001b[38;5;241m=\u001b[39masyncio\u001b[38;5;241m.\u001b[39mFIRST_EXCEPTION,\n\u001b[1;32m    896\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m    897\u001b[0m )\n\u001b[1;32m    899\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[1;32m    900\u001b[0m _panic_or_proceed(done, inflight, step)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/asyncio/tasks.py:418\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing coroutines is forbidden, use tasks explicitly.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    417\u001b[0m loop \u001b[38;5;241m=\u001b[39m events\u001b[38;5;241m.\u001b[39mget_running_loop()\n\u001b[0;32m--> 418\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _wait(fs, timeout, return_when, loop)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/asyncio/tasks.py:525\u001b[0m, in \u001b[0;36m_wait\u001b[0;34m(fs, timeout, return_when, loop)\u001b[0m\n\u001b[1;32m    522\u001b[0m     f\u001b[38;5;241m.\u001b[39madd_done_callback(_on_completion)\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 525\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m waiter\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout_handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import playwright\n",
    "from src import gladia, graph, perception, utils\n",
    "from playwright.async_api import async_playwright\n",
    "from src.utils import graph\n",
    "\n",
    "# question = await gladia.listen()\n",
    "\n",
    "async def listen_for_stop():\n",
    "    global break_out\n",
    "    while True:\n",
    "        question = await gladia.listen()\n",
    "        if \"Stop\" in question:\n",
    "            break_out = True\n",
    "            print(\"Breaking Out!!!!!!\")\n",
    "            break\n",
    "\n",
    "\n",
    "while True:\n",
    "    browser = await async_playwright().start()\n",
    "    browser = await browser.chromium.launch(headless=False, args=None)\n",
    "\n",
    "    # Change the Starting Point for the Web-Browsing Agent\n",
    "    page = await browser.new_page()\n",
    "    _ = await page.goto(\"https://gist.github.com/wynand1004/ec105fd2f457b10d971c09586ec44900\") # This is where we decide the starting point of the agent\n",
    "    question = \"read and scrape the python code from the page\"\n",
    "\n",
    "    event_stream = graph.astream(\n",
    "        {\n",
    "            \"page\": page,\n",
    "            \"input\": question,\n",
    "            \"scratchpad\": [],\n",
    "        },\n",
    "        {\n",
    "            \"recursion_limit\": 50,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    final_answer = None\n",
    "    steps = []\n",
    "    async for event in event_stream:\n",
    "        # We'll display an event stream here\n",
    "        if \"agent\" not in event:\n",
    "            continue\n",
    "        if break_out:\n",
    "            break_out = False\n",
    "            break\n",
    "        event['agent']['input'] = question # Dummny Slot-in Place for further requests from user\n",
    "        pred = event.get(\"agent\", {}).get(\"prediction\") or {}\n",
    "        print(\"Event: \", event)\n",
    "        print(\"Prediction: \\n\", pred)\n",
    "        action = pred.get(\"action\")\n",
    "        action_input = pred.get(\"args\")\n",
    "        print(f\"Action: \\n{len(steps) + 1}. {action}: {action_input}\")\n",
    "        steps.append(f\"{len(steps) + 1}. {action}: {action_input}\")\n",
    "        if \"ANSWER\" in action:\n",
    "            final_answer = action_input[0]\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://gist.github.com/wynand1004/ec105fd2f457b10d971c09586ec44900'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://gist.github.com/wynand1004/ec105fd2f457b10d971c09586ec44900'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Could not parse LLM Output: Thought: The screenshot shows a webpage with Python code related to creating a snake game. The code initializes the game window, creates a snake head, food, and defines a pen for writing the score. The user has asked to read and scrape the Python code from the page.\\n\\nAction: ANSWER; The Python code in the screenshot is for setting up a simple snake game using the turtle graphics library. It includes the following key parts:\\n\\n- Importing the turtle module.\\n- Setting up the game window with a title, background color, size, and turning off screen updates for performance.\\n- Creating the snake's head with a specific shape, color, and initial position.\\n- Defining the snake's food with a shape, color, and position.\\n- Initializing a pen to write the score, with a specific shape, color, and position.\\n- An empty list named 'segments' is defined, presumably for storing the segments of the snake's body as the game progresses.\\n\\nThis code snippet is likely part of a larger program, and additional code would be needed to handle game mechanics like snake movement, collision detection, and updating the score.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event['agent']['prediction']['args']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(nodes={'__start__': Node(id='__start__', data=<class 'pydantic.v1.main.LangGraphInput'>), '__end__': Node(id='__end__', data=<class 'pydantic.v1.main.LangGraphOutput'>), 'agent': Node(id='agent', data=RunnableLambda(afunc=annotate)\n",
       "| RunnableAssign(mapper={\n",
       "    prediction: RunnableLambda(format_descriptions)\n",
       "                | ChatPromptTemplate(input_variables=['bbox_descriptions', 'img', 'input'], input_types={'scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'scratchpad': []}, messages=[SystemMessagePromptTemplate(prompt=[PromptTemplate(input_variables=[], template=\"Imagine you are a robot browsing the web, just like humans. Now you need to complete a task. In each iteration, you will receive an Observation that includes a screenshot of a webpage and some texts. This screenshot will\\nfeature Numerical Labels placed in the TOP LEFT corner of each Web Element. Carefully analyze the visual\\ninformation to identify the Numerical Label corresponding to the Web Element that requires interaction, then follow\\nthe guidelines and choose one of the following actions:\\n\\n1. Click a Web Element.\\n2. Delete existing content in a textbox and then type content.\\n3. Scroll up or down.\\n4. Wait \\n5. Go back\\n7. Return to google to start over.\\n8. Respond with the final answer\\n\\nCorrespondingly, Action should STRICTLY follow the format:\\n\\n- Click [Numerical_Label] \\n- Type [Numerical_Label]; [Content] \\n- Scroll [Numerical_Label or WINDOW]; [up or down] \\n- Wait \\n- GoBack\\n- Google\\n- ANSWER; [content]\\n\\nKey Guidelines You MUST follow:\\n\\n* Action guidelines *\\n1) Execute only one action per iteration.\\n2) When clicking or typing, ensure to select the correct bounding box.\\n3) Numeric labels lie in the top-left corner of their corresponding bounding boxes and are colored the same.\\n\\n* Web Browsing Guidelines *\\n1) Don't interact with useless web elements like Login, Sign-in, donation that appear in Webpages\\n2) Select strategically to minimize time wasted.\\n\\nYour reply should strictly follow the format:\\n\\nThought: {{Your brief thoughts (briefly summarize the info that will help ANSWER)}}\\nAction: {{One Action format you choose}}\\nThen the User will provide:\\nObservation: {{A labeled screenshot Given by User}}\\n\")]), MessagesPlaceholder(variable_name='scratchpad', optional=True), HumanMessagePromptTemplate(prompt=[ImagePromptTemplate(input_variables=['img'], template={'url': 'data:image/png;base64,{img}'}), PromptTemplate(input_variables=['bbox_descriptions'], template='{bbox_descriptions}'), PromptTemplate(input_variables=['input'], template='{input}')])])\n",
       "                | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x111ae4110>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x111889dd0>, model_name='gpt-4-vision-preview', openai_api_key=SecretStr('**********'), openai_proxy='', max_tokens=4096)\n",
       "                | StrOutputParser()\n",
       "                | RunnableLambda(parse)\n",
       "  })), 'update_scratchpad': Node(id='update_scratchpad', data=RunnableLambda(update_scratchpad)), 'Click': Node(id='Click', data=RunnableLambda(afunc=click)\n",
       "| RunnableLambda(lambda observation: {'observation': observation})), 'Type': Node(id='Type', data=RunnableLambda(afunc=type_text)\n",
       "| RunnableLambda(lambda observation: {'observation': observation})), 'Scroll': Node(id='Scroll', data=RunnableLambda(afunc=scroll)\n",
       "| RunnableLambda(lambda observation: {'observation': observation})), 'Wait': Node(id='Wait', data=RunnableLambda(afunc=wait)\n",
       "| RunnableLambda(lambda observation: {'observation': observation})), 'GoBack': Node(id='GoBack', data=RunnableLambda(afunc=go_back)\n",
       "| RunnableLambda(lambda observation: {'observation': observation})), 'Google': Node(id='Google', data=RunnableLambda(afunc=to_google)\n",
       "| RunnableLambda(lambda observation: {'observation': observation})), 'agent_select_tool': Node(id='agent_select_tool', data=RunnableLambda(select_tool))}, edges=[Edge(source='Click', target='update_scratchpad', data=None), Edge(source='GoBack', target='update_scratchpad', data=None), Edge(source='Google', target='update_scratchpad', data=None), Edge(source='Scroll', target='update_scratchpad', data=None), Edge(source='Type', target='update_scratchpad', data=None), Edge(source='Wait', target='update_scratchpad', data=None), Edge(source='__start__', target='agent', data=None), Edge(source='update_scratchpad', target='agent', data=None), Edge(source='agent', target='agent_select_tool', data=None), Edge(source='agent_select_tool', target='agent', data='agent'), Edge(source='agent_select_tool', target='update_scratchpad', data='update_scratchpad'), Edge(source='agent_select_tool', target='Click', data='Click'), Edge(source='agent_select_tool', target='Type', data='Type'), Edge(source='agent_select_tool', target='Scroll', data='Scroll'), Edge(source='agent_select_tool', target='Wait', data='Wait'), Edge(source='agent_select_tool', target='GoBack', data='GoBack'), Edge(source='agent_select_tool', target='Google', data='Google'), Edge(source='agent_select_tool', target='__end__', data='__end__')], branches={})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "graph.get_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                     +-----------+                                                                 \n",
      "                                                                     | __start__ |                                                                 \n",
      "                                                                     +-----------+                                                                 \n",
      "                                                                           *                                                                       \n",
      "                                                                           *                                                                       \n",
      "                                                                           *                                                                       \n",
      "                                                                       +-------+*****                                                              \n",
      "                                                                       | agent |     ***********                                                   \n",
      "                                                                       +-------+                ***********                                        \n",
      "                                                                    ***                                    ***********                             \n",
      "                                                                   *                                                  ***********                  \n",
      "                                                                 **                                                              ***********       \n",
      "                                                     +-------------------+                                                                  ****** \n",
      "                                                 ****| agent_select_tool |******                                                                 * \n",
      "                                      ***************+-------------------+****************                                                       * \n",
      "                           *********** ********    ****      *        **     ******  ****************                                            * \n",
      "                ***********     *******        ****          *          **         *****     *******************                                 * \n",
      "          ******            ****             **             *             **            ***           *****     **********                       * \n",
      "+---------+        +-------+*****   +--------+        +--------+        +--------+        +------+        +------+        ******            ****** \n",
      "| __end__ |        | Click |     ***| GoBack |****    | Google |**      | Scroll |        | Type |      **| Wait |   *******      **********       \n",
      "+---------+        +-------+        +--------+********+--------+  ****  +--------+        +------+  ****  +------+***   **********                 \n",
      "                                                    **************    ****      **       *      ****  ******************                           \n",
      "                                                             *****************    *    **   ******************                                     \n",
      "                                                                      ***********  *  *  ***********                                               \n",
      "                                                                          +-------------------+                                                    \n",
      "                                                                          | update_scratchpad |                                                    \n",
      "                                                                          +-------------------+                                                    \n"
     ]
    }
   ],
   "source": [
    "graph.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
