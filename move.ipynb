{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terminal Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *\n",
    "# chat_with_llama(\"\"\"\"\"\", use_tool=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SERP_API_KEY\"] = \"5affe20ad27423ecb9954ffa3151680c42adadca\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "User message: Search the web for latest tweet from Sam Altman\n",
      "==================================================\n",
      "Web Search Tool\n"
     ]
    }
   ],
   "source": [
    "# OverAll: Search for Snake Game implementation online -> write content into local script -> run & debug & test\n",
    "# 1. Web Search + Voyager\n",
    "out = chat_with_llama(\"\"\"Search the web for latest tweet from Sam Altman\"\"\", use_tool=True)\n",
    "# 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'sam altman twitter - The Economic Times - IndiaTimes',\n",
       " 'link': 'https://economictimes.indiatimes.com/topic/sam-altman-twitter',\n",
       " 'snippet': 'sam altman twitter Latest Breaking News, Pictures, Videos, and Special Reports from The Economic Times. sam altman twitter Blogs, Comments and Archive News ...',\n",
       " 'position': 8}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "User message: read local file street_fighter.py\n",
      "==================================================\n",
      "File Reader Tool\n",
      "print(\"Ryu: Hadouken!\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src import *\n",
    "\n",
    "# Each request can NOT be too lenghty, otherwise function call will not work properly\n",
    "\n",
    "#\n",
    "# Read\n",
    "read_out = chat_with_llama(\"read local file street_fighter.py\")\n",
    "# Run  \n",
    "run_out = chat_with_llama(\"run local file street_fighter.py\")\n",
    "# Write\n",
    "write_in = chat_with_llama(\"write the next 10 lines of street figher game into local file street_fighter.py\")\n",
    "print(out)\n",
    "\n",
    "# Loop back the observation into itself and ask for the next step\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "User message: write the next 10 lines of street figher game into local file street_fighter.py\n",
      "==================================================\n",
      "File Writer Tool\n"
     ]
    }
   ],
   "source": [
    "out = chat_with_llama(\"write the next 10 lines of street figher game into local file street_fighter.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.action import *\n",
    "\n",
    "GROQ_API_KEY = os.environ[\"GROQ_API_KEY\"]\n",
    "E2B_API_KEY = os.environ[\"E2B_API_KEY\"]\n",
    "ANTHROPIC_API_KEY = os.environ[\"ANTHROPIC_API_KEY\"]\n",
    "groq_client = Groq(api_key=GROQ_API_KEY)\n",
    "\n",
    "\n",
    "user_message = \"Write a snake game into a local file named snake_game.py\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": user_message}\n",
    "]\n",
    "\n",
    "MODEL_NAME = \"llama3-70b-8192\"\n",
    "\n",
    "response = groq_client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    "    max_tokens=4096,\n",
    ")\n",
    "\n",
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1239661712.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    .....\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from src import *\n",
    "\n",
    "\n",
    "request = \"run the file snake.py and report the issue\"\n",
    "out = chat_with_llama(request)\n",
    "\n",
    "\n",
    "has_bug = \"Error\" in out\n",
    "if has_bug:\n",
    "    print(\"Please debug\")\n",
    "else:\n",
    "    print(\"think about the next step to complete {initial_goal}\")\n",
    "    ....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<async_generator object Pregel.astream at 0x123d65d50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Deeper\n",
    "from src.utils import graph\n",
    "graph.astream(\"run the file snake.py and report the issue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n",
      "Please ask me a question:\n",
      "final: (en)  you\n",
      "Final transcription received: (en)  you\n",
      "Final Transcription:   you\n",
      "Connected!\n",
      "Please ask me a question:\n",
      "partial: (en)  How is it?\n",
      "partial: (en)  How is everything?\n",
      "partial: (en)  How is everything?\n",
      "final: (en)  How is everything?\n",
      "Final transcription received: (en)  How is everything?\n",
      "Final Transcription:   How is everything?\n",
      "Connected!\n",
      "Please ask me a question:\n",
      "partial: (en)  Voila Baud\n",
      "partial: (en)  What about Don?\n",
      "partial: (en)  What about Donald Trump?\n",
      "partial: (en)  What about Donald Trump?\n",
      "final: (en)  What about Donald Trump?\n",
      "Final transcription received: (en)  What about Donald Trump?\n",
      "Final Transcription:   What about Donald Trump?\n",
      "Connected!\n",
      "Please ask me a question:\n",
      "final: (en)  Stop.\n",
      "Final transcription received: (en)  Stop.\n",
      "Final Transcription:   Stop.\n",
      "Breaking Out!!!!!!\n"
     ]
    }
   ],
   "source": [
    "from src import gladia, graph, perception, utils\n",
    "# Upon the Stop Command this break the loops\n",
    "while True:\n",
    "    question = await gladia.listen()\n",
    "    if \"Stop\" in question:\n",
    "        print(\"Breaking Out!!!!!!\")\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending name='Task-5' coro=<main() running at /var/folders/bt/rngwf7wj73x2zfr_7chtd0jh0000gn/T/ipykernel_28170/776611990.py:89>>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ \n",
      "Search Iteration: 1 \n",
      "------\n",
      "Connected!\n",
      "How can I help:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 13:09:14,313 - Surfer Agent - INFO - Navigating to Google on a new page with question: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partial: (en)  Blade\n",
      "partial: (en)  latest\n",
      "partial: (en)  latest\n",
      "partial: (en)  latest tweet\n",
      "partial: (en)  latest tweet from\n",
      "partial: (en)  latest tweet from\n",
      "partial: (en)  Ladies, tweet from Sam\n",
      "partial: (en)  Ladies, tweet from Sam Oddman\n",
      "partial: (en)  Ladies, tweet from Sam Oddman\n",
      "final: (en)  latest tweet from Sam Altman\n",
      "Final transcription received: (en)  latest tweet from Sam Altman\n",
      "Final Transcription:   latest tweet from Sam Altman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 13:09:19,845 - Surfer Agent - INFO - Getting Question:  latest tweet from Sam Altman\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n",
      "How can I help:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 13:09:22,385 - Surfer Agent - INFO - Updated Agent Input:  latest tweet from Sam Altman\n",
      "2024-05-08 13:09:22,385 - Surfer Agent - INFO - Action: \n",
      "1. Wait: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: \n",
      "1. Wait: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 13:09:33,989 - Surfer Agent - INFO - Updated Agent Input:  latest tweet from Sam Altman\n",
      "2024-05-08 13:09:33,990 - Surfer Agent - INFO - Action: \n",
      "2. Type: ['6', 'What is the highest mountain in the world?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: \n",
      "2. Type: ['6', 'What is the highest mountain in the world?']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping write for channel branch:agent:select_tool:ANSWER; which has no readers\n",
      "2024-05-08 13:09:43,782 - Surfer Agent - INFO - Updated Agent Input:  latest tweet from Sam Altman\n",
      "2024-05-08 13:09:43,782 - Surfer Agent - INFO - Action: \n",
      "3. ANSWER;: ['Mount Everest is the highest mountain in the world, with an elevation of 8,849 meters.']\n",
      "2024-05-08 13:09:43,782 - Surfer Agent - INFO - Final Answer: Mount Everest is the highest mountain in the world, with an elevation of 8,849 meters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: \n",
      "3. ANSWER;: ['Mount Everest is the highest mountain in the world, with an elevation of 8,849 meters.']\n",
      "Final Answer:  Mount Everest is the highest mountain in the world, with an elevation of 8,849 meters.\n",
      "------ \n",
      "Search Iteration: 2 \n",
      "------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 13:09:45,181 - Surfer Agent - INFO - Navigating to Google on a new page with question:  latest tweet from Sam Altman\n",
      "2024-05-08 13:09:50,790 - Surfer Agent - INFO - Updated Agent Input:  latest tweet from Sam Altman\n",
      "2024-05-08 13:09:50,790 - Surfer Agent - INFO - Action: \n",
      "1. Type: ['6', 'Sam Altman latest tweet']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: \n",
      "1. Type: ['6', 'Sam Altman latest tweet']\n",
      "final: (en)  you\n",
      "Final transcription received: (en)  you\n",
      "Final Transcription:   you\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 13:10:11,316 - Surfer Agent - INFO - Getting Question:  you\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n",
      "How can I help:\n"
     ]
    }
   ],
   "source": [
    "from src import gladia, graph, perception, utils\n",
    "import asyncio\n",
    "import playwright\n",
    "from src import gladia, graph, perception, utils\n",
    "from playwright.async_api import async_playwright\n",
    "from src.utils import graph\n",
    "import logging\n",
    "logger = logging.getLogger(\"Surfer Agent\")\n",
    "logger.setLevel(logging.INFO)\n",
    "hander = logging.StreamHandler()\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "hander.setFormatter(formatter)\n",
    "logger.addHandler(hander)\n",
    "\n",
    "\n",
    "# Declare the global variables\n",
    "break_out = False\n",
    "if_end = False\n",
    "question = \"\"\n",
    "search_iter = 0\n",
    "\n",
    "# One Concurrent Async Process | Gradia Streaming Audio Input\n",
    "async def listen_for_stop():\n",
    "    global break_out, if_end, question\n",
    "    while True:\n",
    "        question = await gladia.listen()\n",
    "        logger.info(f\"Getting Question: {question}\")\n",
    "        if \"Stop\" in question:\n",
    "            logger.info(\"Breaking out upon hearing 'Stop'.\")\n",
    "            break_out = True\n",
    "            print(\"Breaking Out!!!!!!\")\n",
    "        if \"End\" in question:\n",
    "            logger.info(\"End the Agent upon hearing 'End'.\")\n",
    "            if_end = True\n",
    "            break\n",
    "\n",
    "async def web_voyager():\n",
    "    global break_out, if_end, question, search_iter\n",
    "\n",
    "    while not if_end:\n",
    "        search_iter += 1\n",
    "        print(f\"------ \\nSearch Iteration: {search_iter} \\n------\")\n",
    "        browser = await async_playwright().start()\n",
    "        browser = await browser.chromium.launch(headless=False, args=None)\n",
    "\n",
    "        # Change the Starting Point for the Web-Browsing Agent\n",
    "        page = await browser.new_page()\n",
    "        _ = await page.goto(\"https://www.google.com\") # This is where we decide the starting point of the agent\n",
    "        logger.info(f\"Navigating to Google on a new page with question: {question}\")\n",
    "\n",
    "        event_stream = graph.astream(\n",
    "            {\n",
    "                \"page\": page,\n",
    "                \"input\": question,\n",
    "                \"scratchpad\": [],\n",
    "            },\n",
    "            {\n",
    "                \"recursion_limit\": 50,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        final_answer = None\n",
    "        steps = []\n",
    "        async for event in event_stream:\n",
    "            # We'll display an event stream here\n",
    "            if \"agent\" not in event:\n",
    "                continue\n",
    "            if break_out:\n",
    "                break_out = False\n",
    "                break\n",
    "            event['agent']['input'] = question # Dummny Slot-in Place for further requests from user\n",
    "            logger.info(f\"Updated Agent Input: {event['agent']['input']}\")\n",
    "\n",
    "            pred = event.get(\"agent\", {}).get(\"prediction\") or {}\n",
    "            # print(\"Event: \", event)\n",
    "            # print(\"Prediction: \\n\", pred)\n",
    "            action = pred.get(\"action\")\n",
    "            action_input = pred.get(\"args\")\n",
    "            logger.info(f\"Action: \\n{len(steps) + 1}. {action}: {action_input}\")\n",
    "            print(f\"Action: \\n{len(steps) + 1}. {action}: {action_input}\")\n",
    "            steps.append(f\"{len(steps) + 1}. {action}: {action_input}\")\n",
    "            if \"ANSWER\" in action:\n",
    "                final_answer = action_input[0]\n",
    "                logger.info(f\"Final Answer: {final_answer}\")\n",
    "                print(\"Final Answer: \", final_answer)\n",
    "                break\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # Create and run the tasks concurrently\n",
    "    task1 = asyncio.create_task(listen_for_stop())\n",
    "    task2 = asyncio.create_task(web_voyager())\n",
    "    await asyncio.gather(task1, task2)\n",
    "\n",
    "# Run the async main function\n",
    "# asyncio.run(main())\n",
    "asyncio.ensure_future(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'break_out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m event:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m break_out:\n\u001b[1;32m     45\u001b[0m     break_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'break_out' is not defined"
     ]
    }
   ],
   "source": [
    "import playwright\n",
    "from src import gladia, graph, perception, utils\n",
    "from playwright.async_api import async_playwright\n",
    "from src.utils import graph\n",
    "\n",
    "# question = await gladia.listen()\n",
    "\n",
    "async def listen_for_stop():\n",
    "    global break_out\n",
    "    while True:\n",
    "        question = await gladia.listen()\n",
    "        if \"Stop\" in question:\n",
    "            break_out = True\n",
    "            print(\"Breaking Out!!!!!!\")\n",
    "            break\n",
    "\n",
    "\n",
    "while True:\n",
    "    browser = await async_playwright().start()\n",
    "    browser = await browser.chromium.launch(headless=False, args=None)\n",
    "\n",
    "    # Change the Starting Point for the Web-Browsing Agent\n",
    "    page = await browser.new_page()\n",
    "    _ = await page.goto(\"https://gist.github.com/wynand1004/ec105fd2f457b10d971c09586ec44900\") # This is where we decide the starting point of the agent\n",
    "    question = \"read and scrape the python code from the page\"\n",
    "\n",
    "    event_stream = graph.astream(\n",
    "        {\n",
    "            \"page\": page,\n",
    "            \"input\": question,\n",
    "            \"scratchpad\": [],\n",
    "        },\n",
    "        {\n",
    "            \"recursion_limit\": 50,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    final_answer = None\n",
    "    steps = []\n",
    "    async for event in event_stream:\n",
    "        # We'll display an event stream here\n",
    "        if \"agent\" not in event:\n",
    "            continue\n",
    "        if break_out:\n",
    "            break_out = False\n",
    "            break\n",
    "        event['agent']['input'] = question # Dummny Slot-in Place for further requests from user\n",
    "        pred = event.get(\"agent\", {}).get(\"prediction\") or {}\n",
    "        print(\"Event: \", event)\n",
    "        print(\"Prediction: \\n\", pred)\n",
    "        action = pred.get(\"action\")\n",
    "        action_input = pred.get(\"args\")\n",
    "        print(f\"Action: \\n{len(steps) + 1}. {action}: {action_input}\")\n",
    "        steps.append(f\"{len(steps) + 1}. {action}: {action_input}\")\n",
    "        if \"ANSWER\" in action:\n",
    "            final_answer = action_input[0]\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://gist.github.com/wynand1004/ec105fd2f457b10d971c09586ec44900'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'read and scrape the python code from the page'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event['agent']['input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Could not parse LLM Output: Thought: The screenshot shows a webpage with Python code related to creating a snake game. The code initializes the game window, creates a snake head, food, and defines a pen for writing the score. The user has asked to read and scrape the Python code from the page.\\n\\nAction: ANSWER; The Python code in the screenshot is for setting up a simple snake game using the turtle graphics library. It includes the following key parts:\\n\\n- Importing the turtle module.\\n- Setting up the game window with a title, background color, size, and turning off screen updates for performance.\\n- Creating the snake's head with a specific shape, color, and initial position.\\n- Defining the snake's food with a shape, color, and position.\\n- Initializing a pen to write the score, with a specific shape, color, and position.\\n- An empty list named 'segments' is defined, presumably for storing the segments of the snake's body as the game progresses.\\n\\nThis code snippet is likely part of a larger program, and additional code would be needed to handle game mechanics like snake movement, collision detection, and updating the score.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event['agent']['prediction']['args']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(nodes={'__start__': Node(id='__start__', data=<class 'pydantic.v1.main.LangGraphInput'>), '__end__': Node(id='__end__', data=<class 'pydantic.v1.main.LangGraphOutput'>), 'agent': Node(id='agent', data=RunnableLambda(afunc=annotate)\n",
       "| RunnableAssign(mapper={\n",
       "    prediction: RunnableLambda(format_descriptions)\n",
       "                | ChatPromptTemplate(input_variables=['bbox_descriptions', 'img', 'input'], input_types={'scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'scratchpad': []}, messages=[SystemMessagePromptTemplate(prompt=[PromptTemplate(input_variables=[], template=\"Imagine you are a robot browsing the web, just like humans. Now you need to complete a task. In each iteration, you will receive an Observation that includes a screenshot of a webpage and some texts. This screenshot will\\nfeature Numerical Labels placed in the TOP LEFT corner of each Web Element. Carefully analyze the visual\\ninformation to identify the Numerical Label corresponding to the Web Element that requires interaction, then follow\\nthe guidelines and choose one of the following actions:\\n\\n1. Click a Web Element.\\n2. Delete existing content in a textbox and then type content.\\n3. Scroll up or down.\\n4. Wait \\n5. Go back\\n7. Return to google to start over.\\n8. Respond with the final answer\\n\\nCorrespondingly, Action should STRICTLY follow the format:\\n\\n- Click [Numerical_Label] \\n- Type [Numerical_Label]; [Content] \\n- Scroll [Numerical_Label or WINDOW]; [up or down] \\n- Wait \\n- GoBack\\n- Google\\n- ANSWER; [content]\\n\\nKey Guidelines You MUST follow:\\n\\n* Action guidelines *\\n1) Execute only one action per iteration.\\n2) When clicking or typing, ensure to select the correct bounding box.\\n3) Numeric labels lie in the top-left corner of their corresponding bounding boxes and are colored the same.\\n\\n* Web Browsing Guidelines *\\n1) Don't interact with useless web elements like Login, Sign-in, donation that appear in Webpages\\n2) Select strategically to minimize time wasted.\\n\\nYour reply should strictly follow the format:\\n\\nThought: {{Your brief thoughts (briefly summarize the info that will help ANSWER)}}\\nAction: {{One Action format you choose}}\\nThen the User will provide:\\nObservation: {{A labeled screenshot Given by User}}\\n\")]), MessagesPlaceholder(variable_name='scratchpad', optional=True), HumanMessagePromptTemplate(prompt=[ImagePromptTemplate(input_variables=['img'], template={'url': 'data:image/png;base64,{img}'}), PromptTemplate(input_variables=['bbox_descriptions'], template='{bbox_descriptions}'), PromptTemplate(input_variables=['input'], template='{input}')])])\n",
       "                | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x111ae4110>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x111889dd0>, model_name='gpt-4-vision-preview', openai_api_key=SecretStr('**********'), openai_proxy='', max_tokens=4096)\n",
       "                | StrOutputParser()\n",
       "                | RunnableLambda(parse)\n",
       "  })), 'update_scratchpad': Node(id='update_scratchpad', data=RunnableLambda(update_scratchpad)), 'Click': Node(id='Click', data=RunnableLambda(afunc=click)\n",
       "| RunnableLambda(lambda observation: {'observation': observation})), 'Type': Node(id='Type', data=RunnableLambda(afunc=type_text)\n",
       "| RunnableLambda(lambda observation: {'observation': observation})), 'Scroll': Node(id='Scroll', data=RunnableLambda(afunc=scroll)\n",
       "| RunnableLambda(lambda observation: {'observation': observation})), 'Wait': Node(id='Wait', data=RunnableLambda(afunc=wait)\n",
       "| RunnableLambda(lambda observation: {'observation': observation})), 'GoBack': Node(id='GoBack', data=RunnableLambda(afunc=go_back)\n",
       "| RunnableLambda(lambda observation: {'observation': observation})), 'Google': Node(id='Google', data=RunnableLambda(afunc=to_google)\n",
       "| RunnableLambda(lambda observation: {'observation': observation})), 'agent_select_tool': Node(id='agent_select_tool', data=RunnableLambda(select_tool))}, edges=[Edge(source='Click', target='update_scratchpad', data=None), Edge(source='GoBack', target='update_scratchpad', data=None), Edge(source='Google', target='update_scratchpad', data=None), Edge(source='Scroll', target='update_scratchpad', data=None), Edge(source='Type', target='update_scratchpad', data=None), Edge(source='Wait', target='update_scratchpad', data=None), Edge(source='__start__', target='agent', data=None), Edge(source='update_scratchpad', target='agent', data=None), Edge(source='agent', target='agent_select_tool', data=None), Edge(source='agent_select_tool', target='agent', data='agent'), Edge(source='agent_select_tool', target='update_scratchpad', data='update_scratchpad'), Edge(source='agent_select_tool', target='Click', data='Click'), Edge(source='agent_select_tool', target='Type', data='Type'), Edge(source='agent_select_tool', target='Scroll', data='Scroll'), Edge(source='agent_select_tool', target='Wait', data='Wait'), Edge(source='agent_select_tool', target='GoBack', data='GoBack'), Edge(source='agent_select_tool', target='Google', data='Google'), Edge(source='agent_select_tool', target='__end__', data='__end__')], branches={})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "graph.get_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                     +-----------+                                                                 \n",
      "                                                                     | __start__ |                                                                 \n",
      "                                                                     +-----------+                                                                 \n",
      "                                                                           *                                                                       \n",
      "                                                                           *                                                                       \n",
      "                                                                           *                                                                       \n",
      "                                                                       +-------+*****                                                              \n",
      "                                                                       | agent |     ***********                                                   \n",
      "                                                                       +-------+                ***********                                        \n",
      "                                                                    ***                                    ***********                             \n",
      "                                                                   *                                                  ***********                  \n",
      "                                                                 **                                                              ***********       \n",
      "                                                     +-------------------+                                                                  ****** \n",
      "                                                 ****| agent_select_tool |******                                                                 * \n",
      "                                      ***************+-------------------+****************                                                       * \n",
      "                           *********** ********    ****      *        **     ******  ****************                                            * \n",
      "                ***********     *******        ****          *          **         *****     *******************                                 * \n",
      "          ******            ****             **             *             **            ***           *****     **********                       * \n",
      "+---------+        +-------+*****   +--------+        +--------+        +--------+        +------+        +------+        ******            ****** \n",
      "| __end__ |        | Click |     ***| GoBack |****    | Google |**      | Scroll |        | Type |      **| Wait |   *******      **********       \n",
      "+---------+        +-------+        +--------+********+--------+  ****  +--------+        +------+  ****  +------+***   **********                 \n",
      "                                                    **************    ****      **       *      ****  ******************                           \n",
      "                                                             *****************    *    **   ******************                                     \n",
      "                                                                      ***********  *  *  ***********                                               \n",
      "                                                                          +-------------------+                                                    \n",
      "                                                                          | update_scratchpad |                                                    \n",
      "                                                                          +-------------------+                                                    \n"
     ]
    }
   ],
   "source": [
    "graph.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
